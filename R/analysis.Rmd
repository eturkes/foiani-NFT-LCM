---
title: "Foiani NFT LCM Analysis"
knit: (function(inputFile, encoding) {
  rmarkdown::render(
    inputFile,
    encoding = encoding,
    output_file = file.path("..", "results", "analysis.html")
  )})
---

# Data Cleaning and Prep

In this section, the raw data is read into R and manipulated as necessary to create a `SummarizedExperiment` object for use with the `DEP` package.

```{r}
#    This file is part of foiani-NFT-LCM.
#    Copyright (C) 2023  Emir Turkes, Martha Foiani, UK DRI at UCL
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#    Emir Turkes can be contacted at emir.turkes@eturkes.com

# Best way to load a bunch of packages without tons of messages being produced.
# -----------------------------------------------------------------------------
packages <- c(
  "DEP", "SummarizedExperiment", "plotly", "limma", "dplyr", "DT", "ComplexHeatmap", "colorRamp2", "RColorBrewer",
  "tibble", "scales"
)
invisible(suppressPackageStartupMessages(lapply(packages, FUN = library, character.only = TRUE)))
# -----------------------------------------------------------------------------

`%notin%` <- Negate(`%in%`) # Add custom function.

knitr::opts_chunk$set(dpi = 300, fig.width = 12, fig.height = 8) # Produce high-quality images with better sizes.

data <- read.delim(file.path("..", "data", "report.pg_matrix.tsv")) # Read in data.

# Use some regex magic to tidy up sample names.
# ---------------------------------------------
colnames(data) <- sub("^.*?([0-9]+_[^_]+_[0-9]+_[^_]+).*", replacement = "\\1", x = colnames(data))
colnames(data) <- c(colnames(data)[1:5], paste0("Donor", colnames(data)[6:60]))
colnames(data) <- c(
  colnames(data)[1:5], sub("(.*_){1}(\\d+)_.+", replacement = "\\1TechRep\\2", colnames(data)[6:60])
)
# ---------------------------------------------

# Remove proteins that do not have a gene annotation.
# ---------------------------------------------------
remove <- which(data$Genes == "")
if (length(remove > 0)) { # Need to check that "remove" is non-empty.
  data <- data[-remove, ]
}
# ---------------------------------------------------

# Adds "name" and "id" columns to end of the data frame that contain one gene and protein name per row, as
# opposed to several semicolon delimited entries as seen in the "Genes" and "Protein.Ids" columns.
# --------------------------------------------------------------------------------------------------------
data <- make_unique(data, names = "Genes", ids = "Protein.Ids")
# --------------------------------------------------------------------------------------------------------

# Create a data frame for metadata.
# "label", "condition", and "replicate" are required for the DEP package.
# -----------------------------------------------------------------------
experimental_design <- data.frame(
  label = colnames(data)[6:60],
  condition = sub("^[^_]*_([^_]*).*", replacement = "\\1", colnames(data)[6:60]),
  techrep = sub(".*_", replacement = "", colnames(data)[6:60]),
  donor = sub("_.*", replacement = "", colnames(data)[6:60])
)
experimental_design$replicate <- paste(experimental_design$donor, experimental_design$techrep, sep = "_")
# -----------------------------------------------------------------------

# Create SummarizedExperiment object for use with DEP.
# ----------------------------------------------------
data <- make_se(data, columns = 6:60, expdesign = experimental_design)
data_bak <- data # Make a copy of unprocessed data for later.
# ----------------------------------------------------
```

# Preprocessing

Basic QC visualisations are shown here and the data is normalised and imputed, using standard methods.

```{r}
hist(assay(data), n = 100) # Visualise data distribution.

# Various plotting methods to assess missing values.
# --------------------------------------------------
plot_numbers(data)
plot_frequency(data)
plot_detect(data)
plot_missval(data)
# --------------------------------------------------

# Must remove samples where no proteins at all were detected.
# -----------------------------------------------------------
remove <- which(colSums(assay(data), na.rm = TRUE) == 0)
if (length(remove > 0)) {
  data <- data[ , -remove]
}
# -----------------------------------------------------------

# Normalise data using a variance stabilising transformation (VSN).
# -----------------------------------------------------------------
orig <- data # Make a copy of the pre-normalised data for plotting later.
data <- normalize_vsn(data)
meanSdPlot(data)
plot_normalization(orig)
plot_normalization(data)
# -----------------------------------------------------------------

# Impute data using the k-nearest neighbors algorithmn (KNN).
# -----------------------------------------------------------
orig <- data
data <- impute(data, fun = "knn", colmax = 100)
plot_imputation(orig, data)
# -----------------------------------------------------------

rm(orig) # Remove temporary objects.
```

# PCA

Create PCA plots for the data.
The plots have interactive features when moused-over.

```{r, dpi = 96}
# Manually perform PCA for more flexible plotting.
# ------------------------------------------------
pca <- prcomp(t(assay(data))) # Transpose because PCA assumes rows are observations and columns are variables.
df <- as.data.frame(predict(pca)[ , 1:2]) # Extract the first two PCs.
df$Condition <- data$condition
df$Donor <- data$donor
df$Sample <- colnames(data)
summary <- summary(pca)$importance # Extract variance explained.
# ------------------------------------------------

# Plot PCA using ggplot2 rather than DEP's built-in function.
# ggplots are also wrapped in ggplotly for interactivity.
# -----------------------------------------------------------
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Sample, text = paste("Donor:", Donor))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Donor, text = paste("Sample:", Sample))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
# -----------------------------------------------------------
```

# Subsetting

Subset the data to those samples that group together on the basis of missing fewer values.

```{r}
keep <- rownames(df[which(df$PC1 < 0 & df$PC2 > 0), ]) # Top left of PCA seems to have highest quality results.
data_bak_sub <- data_bak[ , keep] # Use unprocessed copy to visualise missing values.

plot_numbers(data_bak_sub)

remove <- which(data_bak_sub$donor == "Donor9") # Remove Donor9 because there are no good tangle-neg. samples.
data_bak_sub <- data_bak_sub[ , -remove]

plot_numbers(data_bak_sub)

# Apply subsetting to the processed dataset.
# ------------------------------------------
data <- data[ , keep]
data <- data[ , -remove]
# ------------------------------------------
```

# PCA

Create more PCA plots after subsetting.

```{r, dpi = 96}
# Manually perform PCA for more flexible plotting.
# ------------------------------------------------
pca <- prcomp(t(assay(data))) # Transpose because PCA assumes rows are observations and columns are variables.
df <- as.data.frame(predict(pca)[ , 1:2]) # Extract the first two PCs.
df$Condition <- data$condition
df$Donor <- data$donor
df$Sample <- colnames(data)
summary <- summary(pca)$importance # Extract variance explained.
# ------------------------------------------------

# Plot PCA using ggplot2 rather than DEP's built-in function.
# ggplots are also wrapped in ggplotly for interactivity.
# -----------------------------------------------------------
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Sample, text = paste("Donor:", Donor))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Donor, text = paste("Sample:", Sample))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
# -----------------------------------------------------------
```

# Reprocessing

We start with the unprocessed data again, this time with the low-quality samples removed in order to achieve better preprocessing.
We also apply a more sophisticated imputation pipeline.

```{r}
#' Custom version of \code{plot_detect} from DEP which attempts to plot the intersection at which
#' MNAR becomes MAR.
#'
#' \code{plot_detect_custom} generates density and CumSum plots
#' of protein intensities with and without missing values
#'
#' @param se SummarizedExperiment,
#' Data object with missing values.
#' @return Density and CumSum plots of intensities of
#' proteins with and without missing values
#' (generated by \code{\link[ggplot2]{ggplot}}).
#' @examples
#' # Load example
#' data <- UbiLength
#' data <- data[data$Reverse != "+" & data$Potential.contaminant != "+",]
#' data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")
#'
#' # Make SummarizedExperiment
#' columns <- grep("LFQ.", colnames(data_unique))
#' exp_design <- UbiLength_ExpDesign
#' se <- make_se(data_unique, columns, exp_design)
#'
#' # Filter
#' filt <- filter_missval(se, thr = 0)
#'
#' # Plot intensities of proteins with missing values
#' plot_detect_custom(filt)
#' @export
plot_detect_custom <- function(se, elbow = FALSE, threshold = 0.35) {
  # Show error if inputs are not the required classes
  assertthat::assert_that(inherits(se, "SummarizedExperiment"))

  se_assay <- assay(se)
  # Show error if there are no missing values
  if(!any(is.na(se_assay))) {
    stop("No missing values in '", deparse(substitute(se)), "'",
         call. = FALSE)
  }

  # Get a long data.frame of the assay data annotated with sample info
  df <- se_assay %>%
    data.frame() %>%
    rownames_to_column() %>%
    tidyr::gather(ID, val, -rowname)

  # Get a summarized table with mean protein intensities and
  # indication whether the protein has missing values
  stat <- df %>%
    group_by(rowname) %>%
    summarize(mean = mean(val, na.rm = TRUE), missval = any(is.na(val)))

  # Calculate cumulative fraction
  cumsum <- stat %>%
    group_by(missval) %>%
    arrange(mean) %>%
    mutate(num = 1, cs = cumsum(num), cs_frac = cs/n())

  # Create a stacked probability density plot instead of the usual plots.
  # ---------------------------------------------------------------------
  color <- c("#74A9CF", "#045A8D")
  p <- ggplot(stat, aes(mean, ..count.., fill = missval, color = missval)) +
    geom_density(position = "fill") +
    scale_x_continuous(expression(log[2]~"Intensity"), expand = c(0, 0), n.breaks = 10) +
    scale_y_continuous("Relative proportion", labels = percent, expand = c(0, 0), n.breaks = 10) +
    theme_DEP1() +
    scale_color_manual("Missing values", values = color) +
    scale_fill_manual("Missing values", values = color)
  # ---------------------------------------------------------------------

  if (elbow == TRUE) {

    # Extract X and Y values of the curve.
    # ------------------------------------
    p_build <- ggplot_build(p)
    x <- p_build$data[[1]]$x
    y <- p_build$data[[1]]$y
    # ------------------------------------

    # Find "elbow" points of the curve.
    # The method is adapted from content on Stack Overflow.
    # https://stackoverflow.com/questions/41518870/finding-the-elbow-knee-in-a-curve/
    # Question asked by: dan https://stackoverflow.com/users/5548896/dan
    # Answer given by: Sandipan Dey https://stackoverflow.com/users/4706171/sandipan-dey
    # ----------------------------------------------------------------------------------
    d1 <- diff(y) / diff(x)
    d2 <- diff(d1) / diff(x[-1])
    idx <- which(abs(d2) > threshold)
    # ----------------------------------------------------------------------------------

    # Add cutoff line at the minimum elbow point to the plot.
    # -------------------------------------------------------
    p <- p + geom_vline(xintercept = min(x[idx]))
    # -------------------------------------------------------
  }
  p
}

data <- data_bak_sub # Make the main data object the unprocessed version.

hist(assay(data), n = 100) # Visualise data distribution.

# Various plotting methods to assess missing values.
# --------------------------------------------------
plot_numbers(data)
plot_frequency(data)
plot_detect(data)
plot_missval(data)
# --------------------------------------------------

# Replace proteins missing entirely in a condition with minimum value per condition in random
# samples.
# -------------------------------------------------------------------------------------------
for (condition in unique(data$condition)) {
  min <- min(assay(data)[ , which(data$condition == condition)], na.rm = TRUE)
  replace <- which(is.na(rowMeans(assay(data)[ , which(data$condition == condition)], TRUE)))
  set.seed(1)
  col <- sample(which(data$condition == condition), length(replace), TRUE)
  for (i in seq_along(replace)) {
    assay(data)[replace[i], col[i]] <- min
  }
}
# -------------------------------------------------------------------------------------------

# Find intensity cutoff point at which MNAR becomes MAR by finding the inflection point of intensity
# where the proportion of proteins with missing values dramatically level off.
# We do this separately for each condition.
# --------------------------------------------------------------------------------------------------
plot <- plot_detect_custom(data[ , which(data$condition == "Neg")])
plot_data <- ggplot_build(plot)
Neg_MNAR_cutoff <- 12.4
cat(paste0("For Neg.\nCutoff at ", Neg_MNAR_cutoff))
plot + geom_vline(xintercept = Neg_MNAR_cutoff) + ggtitle("Neg")

plot <- plot_detect_custom(data[ , which(data$condition == "Pos")])
plot_data <- ggplot_build(plot)
Pos_MNAR_cutoff <- 12.4
cat(paste0("For Pos.\nCutoff at ", Pos_MNAR_cutoff))
plot + geom_vline(xintercept = Pos_MNAR_cutoff) + ggtitle("Pos")
# --------------------------------------------------------------------------------------------------

# Order each condition by row means and select the last protein to be included as MNAR.
# We choose row means over medians because high expression outliers may be decent indication a
# protein is not MNAR.
# --------------------------------------------------------------------------------------------
Neg_order <- order(rowMeans(assay(data)[ , which(data$condition == "Neg")], TRUE))
data <- data[Neg_order, ]
Neg_MNAR <- names(
  which(rowMeans(assay(data)[ , which(data$condition == "Neg")], TRUE) < Neg_MNAR_cutoff)
)

Pos_order <- order(rowMeans(assay(data)[ , which(data$condition == "Pos")], TRUE))
data <- data[Pos_order, ]
Pos_MNAR <- names(
  which(rowMeans(assay(data)[ , which(data$condition == "Pos")], TRUE) < Pos_MNAR_cutoff)
)
# --------------------------------------------------------------------------------------------

# In each condition, remove MAR (non-MNAR) proteins where the majority are missing.
# Generally, we have found that MAR imputation with a majority of missing values leads to suspect
# imputation.
# MNAR imputation however, does not seem to suffer from this limitation, and in fact it is logical
# that MNAR proteins would have a high number of missing values.
# ------------------------------------------------------------------------------------------------
Neg_data <- data[ , which(data$condition == "Neg")]
Neg_data <- Neg_data[rownames(Neg_data) %notin% Neg_MNAR, ]
missing_data <- assay(Neg_data) %>% data.frame(.)
missing_data <- ifelse(is.na(missing_data), 0, 1)
discard <- which(rowSums(missing_data, TRUE) < 5) # TODO: Automate this.
if (length(discard) > 0) {
  Neg_data <- Neg_data[-discard, ]
}
print(paste0("Removed ", length(discard), " proteins from Neg group."))

Pos_data <- data[ , which(data$condition == "Pos")]
Pos_data <- Pos_data[rownames(Pos_data) %notin% Pos_MNAR, ]
missing_data <- assay(Pos_data) %>% data.frame(.)
missing_data <- ifelse(is.na(missing_data), 0, 1)
discard <- which(rowSums(missing_data, TRUE) < 5) # TODO: Automate this.
if (length(discard) > 0) {
  Pos_data <- Pos_data[-discard, ]
}
print(paste0("Removed ", length(discard), " proteins from Pos group."))
# ------------------------------------------------------------------------------------------------

# In order to ensure that all conditions have MAR proteins with majority non-missing values, we
# perform the unions below.
# For example, out of the proteins that pass this QC in one condition, or have no missing values, we
# only keep those that pass this QC, have no missing values, or are MNAR in all other conditions as
# well.
# --------------------------------------------------------------------------------------------------
Neg_MAR <- rownames(Neg_data)[
  rownames(Neg_data) %in% Pos_MNAR | rownames(Neg_data) %in% rownames(Pos_data)
]
Pos_MAR <- rownames(Pos_data)[
  rownames(Pos_data) %in% Neg_MNAR | rownames(Pos_data) %in% rownames(Neg_data)
]

rm(Neg_data, Pos_data)
MAR <- unique(append(Neg_MAR, Pos_MAR))

Neg_MNAR_passQC <- Neg_MNAR[Neg_MNAR %in% Pos_MAR | Neg_MNAR %in% Pos_MNAR]
Pos_MNAR_passQC <- Pos_MNAR[Pos_MNAR %in% Neg_MAR | Pos_MNAR %in% Neg_MNAR]

MNAR <- unique(append(Neg_MNAR_passQC, Pos_MNAR_passQC))
# --------------------------------------------------------------------------------------------------

# We join MAR and MNAR lists and subset the data.
# -----------------------------------------------
keep <- unique(append(MAR, MNAR))
data <- data[rownames(data) %in% keep, ]
# -----------------------------------------------

# Normalise data using a variance stabilising transformation (VSN).
# -----------------------------------------------------------------
orig <- data # Make a copy of the pre-normalised data for plotting later.
data <- normalize_vsn(data)
meanSdPlot(data)
plot_normalization(orig)
plot_normalization(data)
# -----------------------------------------------------------------

# The main imputation code for normalised data.
# ---------------------------------------------
orig <- data

impute1 <- data[ , which(data$condition == "Neg")]
impute_vector <- rownames(impute1) %in% Neg_MNAR # Logical vector specifying MNAR.
set.seed(1)
impute1 <- impute(impute1, "mixed", randna = !impute_vector, mar = "knn", mnar = "MinProb")

impute2 <- data[ , which(data$condition == "Pos")]
impute_vector <- rownames(impute2) %in% Pos_MNAR
set.seed(1)
impute2 <- impute(impute2, "mixed", randna = !impute_vector, mar = "knn", mnar = "MinProb")

assay(data, withDimnames = FALSE) <- cbind(assay(impute1), assay(impute2))

plot_imputation(orig, data)
# ---------------------------------------------

rm(orig) # Remove temporary objects.
```

# PCA

Create more PCA plots with the reprocessed data.

```{r, dpi = 96}
# Manually perform PCA for more flexible plotting.
# ------------------------------------------------
pca <- prcomp(t(assay(data))) # Transpose because PCA assumes rows are observations and columns are variables.
df <- as.data.frame(predict(pca)[ , 1:2]) # Extract the first two PCs.
df$Condition <- data$condition
df$Donor <- data$donor
df$Sample <- colnames(data)
summary <- summary(pca)$importance # Extract variance explained.
# ------------------------------------------------

# Plot PCA using ggplot2 rather than DEP's built-in function.
# ggplots are also wrapped in ggplotly for interactivity.
# -----------------------------------------------------------
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Sample, text = paste("Donor:", Donor))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
ggplotly(
  ggplot(df, aes(PC1, PC2, color = Donor, text = paste("Sample:", Sample))) +
    geom_point(aes(shape = Condition), size = 2, stroke = 1) +
    labs(
      x = paste0("PC1: ", round(summary[2, 1] * 100, digits = 1), "% of Variance Explained"),
      y = paste0("PC2: ", round(summary[2, 2] * 100, digits = 1), "% of Variance Explained")
    ) +
    theme_bw()
)
# -----------------------------------------------------------
```

# Differential Expression

We test for differential expression between tangle-positive and tangle-negative samples.
In order to account to technical replication, we include a custom version of the `test_diff` function from DEP.
We also include a custom version of `datatable` from DT, which allows downloading of the data.

```{r}
#' Custom version of \code{test_diff} from DEP which accounts for technical replicates.
#'
#' \code{test_diff_custom} performs a differential enrichment test based on
#' protein-wise linear models and empirical Bayes
#' statistics using \pkg{limma}. False Discovery Rates are estimated
#' using \pkg{fdrtool}.
#'
#' @param se SummarizedExperiment,
#' Proteomics data (output from \code{\link{make_se}()} or
#' \code{\link{make_se_parse}()}). It is adviced to first remove
#' proteins with too many missing values using \code{\link{filter_missval}()},
#' normalize the data using \code{\link{normalize_vsn}()} and
#' impute remaining missing values using \code{\link{impute}()}.
#' @param type "control", "all" or "manual",
#' The type of contrasts that will be tested.
#' This can be all possible pairwise comparisons ("all"),
#' limited to the comparisons versus the control ("control"), or
#' manually defined contrasts ("manual").
#' @param control Character(1),
#' The condition to which contrasts are generated if type = "control"
#' (a control condition would be most appropriate).
#' @param test Character,
#' The contrasts that will be tested if type = "manual".
#' These should be formatted as "SampleA_vs_SampleB" or
#' c("SampleA_vs_SampleC", "SampleB_vs_SampleC").
#' @param design_formula Formula,
#' Used to create the design matrix.
#' @return A SummarizedExperiment object
#' containing fdr estimates of differential expression.
#' @examples
#' # Load example
#' data <- UbiLength
#' data <- data[data$Reverse != "+" & data$Potential.contaminant != "+",]
#' data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")
#'
#' # Make SummarizedExperiment
#' columns <- grep("LFQ.", colnames(data_unique))
#' exp_design <- UbiLength_ExpDesign
#' se <- make_se(data_unique, columns, exp_design)
#'
#' # Filter, normalize and impute missing values
#' filt <- filter_missval(se, thr = 0)
#' norm <- normalize_vsn(filt)
#' imputed <- impute(norm, fun = "MinProb", q = 0.01)
#'
#' # Test for differentially expressed proteins
#' diff <- test_diff_custom(imputed, "control", "Ctrl")
#' diff <- test_diff_custom(imputed, "manual",
#'     test = c("Ubi4_vs_Ctrl", "Ubi6_vs_Ctrl"))
#'
#' # Test for differentially expressed proteins with a custom design formula
#' diff <- test_diff_custom(imputed, "control", "Ctrl",
#'     design_formula = formula(~ 0 + condition + replicate))
#' @export
test_diff_custom <- function(se, type = c("control", "all", "manual"),
                      control = NULL, test = NULL,
                      design_formula = formula(~ 0 + condition)) {

  # Show error if inputs are not the required classes
  assertthat::assert_that(inherits(se, "SummarizedExperiment"),
                          is.character(type),
                          class(design_formula) == "formula")

  # Show error if inputs do not contain required columns
  type <- match.arg(type)

  col_data <- colData(se)
  raw <- assay(se)

  if(any(!c("name", "ID") %in% colnames(rowData(se, use.names = FALSE)))) {
    stop("'name' and/or 'ID' columns are not present in '",
         deparse(substitute(se)),
         "'\nRun make_unique() and make_se() to obtain the required columns",
         call. = FALSE)
  }
  if(any(!c("label", "condition", "replicate") %in% colnames(col_data))) {
    stop("'label', 'condition' and/or 'replicate' columns are not present in '",
         deparse(substitute(se)),
         "'\nRun make_se() or make_se_parse() to obtain the required columns",
         call. = FALSE)
  }
  if(any(is.na(raw))) {
    warning("Missing values in '", deparse(substitute(se)), "'")
  }

  if(!is.null(control)) {
    # Show error if control input is not valid
    assertthat::assert_that(is.character(control),
                            length(control) == 1)
    if(!control %in% unique(col_data$condition)) {
      stop("run test_diff_custom() with a valid control.\nValid controls are: '",
           paste0(unique(col_data$condition), collapse = "', '"), "'",
           call. = FALSE)
    }
  }

  # variables in formula
  variables <- terms.formula(design_formula) %>%
    attr(., "variables") %>%
    as.character() %>%
    .[-1]

  # Throw error if variables are not col_data columns
  if(any(!variables %in% colnames(col_data))) {
    stop("run make_diff() with an appropriate 'design_formula'")
  }
  if(variables[1] != "condition") {
    stop("first factor of 'design_formula' should be 'condition'")
  }

  # Obtain variable factors
  for(var in variables) {
    temp <- factor(col_data[[var]])
    assign(var, temp)
  }

  # Make an appropriate design matrix
  design <- model.matrix(design_formula, data = environment())
  colnames(design) <- gsub("condition", "", colnames(design))

  # Generate contrasts to be tested
  # Either make all possible combinations ("all"),
  # only the contrasts versus the control sample ("control") or
  # use manual contrasts
  conditions <- as.character(unique(condition))
  if(type == "all") {
    # All possible combinations
    cntrst <- apply(utils::combn(conditions, 2), 2, paste, collapse = " - ")

    if(!is.null(control)) {
      # Make sure that contrast containing
      # the control sample have the control as denominator
      flip <- grep(paste("^", control, sep = ""), cntrst)
      if(length(flip) >= 1) {
        cntrst[flip] <- cntrst[flip] %>%
          gsub(paste(control, "- ", sep = " "), "", .) %>%
          paste(" - ", control, sep = "")
      }
    }

  }
  if(type == "control") {
    # Throw error if no control argument is present
    if(is.null(control))
      stop("run test_diff_custom(type = 'control') with a 'control' argument")

    # Make contrasts
    cntrst <- paste(conditions[!conditions %in% control],
                    control,
                    sep = " - ")
  }
  if(type == "manual") {
    # Throw error if no test argument is present
    if(is.null(test)) {
      stop("run test_diff_custom(type = 'manual') with a 'test' argument")
    }
    assertthat::assert_that(is.character(test))

    if(any(!unlist(strsplit(test, "_vs_")) %in% conditions)) {
      stop("run test_diff_custom() with valid contrasts in 'test'",
           ".\nValid contrasts should contain combinations of: '",
           paste0(conditions, collapse = "', '"),
           "', for example '", paste0(conditions[1], "_vs_", conditions[2]),
           "'.", call. = FALSE)
    }

    cntrst <- gsub("_vs_", " - ", test)

  }
  # Print tested contrasts
  message("Tested contrasts: ",
          paste(gsub(" - ", "_vs_", cntrst), collapse = ", "))

  # Test for differential expression by empirical Bayes moderation
  # of a linear model on the predefined contrasts
  corr_fit <- duplicateCorrelation(raw, design, block = col_data$donor)
  fit <- lmFit(raw, design, block = col_data$donor, cor = corr_fit$consensus)
  made_contrasts <- makeContrasts(contrasts = cntrst, levels = design)
  contrast_fit <- contrasts.fit(fit, made_contrasts)

  if(any(is.na(raw))) {
    for(i in cntrst) {
      covariates <- strsplit(i, " - ") %>% unlist
      single_contrast <- makeContrasts(contrasts = i, levels = design[, covariates])
      single_contrast_fit <- contrasts.fit(fit[, covariates], single_contrast)
      contrast_fit$coefficients[, i] <- single_contrast_fit$coefficients[, 1]
      contrast_fit$stdev.unscaled[, i] <- single_contrast_fit$stdev.unscaled[, 1]
    }
  }

  eB_fit <- eBayes(contrast_fit)

  # function to retrieve the results of
  # the differential expression test using 'fdrtool'
  retrieve_fun <- function(comp, fit = eB_fit){
    res <- topTable(fit, sort.by = "t", coef = comp,
                    number = Inf, confint = TRUE)
    res <- res[!is.na(res$t),]
    fdr_res <- fdrtool::fdrtool(res$t, plot = FALSE, verbose = FALSE)
    res$qval <- fdr_res$qval
    res$lfdr <- fdr_res$lfdr
    res$comparison <- rep(comp, dim(res)[1])
    res <- tibble::rownames_to_column(res)
    return(res)
  }

  # Retrieve the differential expression test results
  limma_res <- purrr::map_df(cntrst, retrieve_fun)

  # Select the logFC, CI and qval variables
  table <- limma_res %>%
    select(rowname, logFC, CI.L, CI.R, P.Value, qval, comparison) %>%
    mutate(comparison = gsub(" - ", "_vs_", comparison)) %>%
    tidyr::gather(variable, value, -c(rowname,comparison)) %>%
    mutate(variable = recode(variable, logFC = "diff", P.Value = "p.val", qval = "p.adj")) %>%
    tidyr::unite(temp, comparison, variable) %>%
    tidyr::spread(temp, value)
  rowData(se) <- merge(rowData(se, use.names = FALSE), table,
                       by.x = "name", by.y = "rowname", all.x = TRUE, sort=FALSE)
  return(se)
}

#' Adds download buttons and horizontal scrolling to \code{"DT::datatable"}.
#'
#' @param dt A data.table object.
#' @examples
#' datatable_download(dt = data_table)
#'
datatable_download <- function(dt) {

  datatable(
    dt,
    list(
      scrollX = TRUE, dom = "Blfrtip",
      buttons = list(
        "copy", "print",
        list(extend = "collection", buttons = c("csv", "excel", "pdf"), text = "Download")
      )
    ),
    extensions = "Buttons"
  )
}

data_results <- test_diff_custom(data, type = "control", control = "Neg", design_formula = ~ 0 + condition)
data_results <- add_rejections(data_results, lfc = 0) # Set significance at 0.05 adjP and 0 log2 fold change.
results <- get_results(data_results)
sig <- results[results$significant, ]
print(paste0(nrow(sig), " significant proteins."))

results <- results[match(sort(results$Pos_vs_Neg_p.val), results$Pos_vs_Neg_p.val), ] # Sort by unadjusted p-val.
datatable_download(results) # Careful, there is no p-value cutoff applied.

heatmap_data <- assay(data)[rownames(data) %in% results$name[1:20], ] # Plot top 20 proteins.
colour <- colorRamp2( # Create a custom colour palette.
  c(min(assay(data)), (max(assay(data)) + min(assay(data))) / 2, max(assay(data))),
  c(brewer.pal(3, "RdYlBu")[3], brewer.pal(3, "RdYlBu")[2], brewer.pal(3, "RdYlBu")[1])
)
Heatmap(
  heatmap_data,
  col = colour,
  column_names_side = "top",
  cluster_columns = FALSE,
  cluster_rows = FALSE,
  row_order = match(results$name[1:20], rownames(heatmap_data)),
  column_split = data$condition,
  column_gap = unit(2, "mm"),
  heatmap_legend_param = list(title = "log2 Intensity", title_position = "leftcenter-rot"),
)

heatmap_data <- t( # Perform row-wise scaling.
  apply(heatmap_data, MARGIN = 1, FUN = function (x) ((2 * (x - min(x)) / (max(x) - min(x))) - 1))
)
colour2 <- colorRamp2(
  c(min(heatmap_data), (max(heatmap_data) + min(heatmap_data)) / 2, max(heatmap_data)),
  c(brewer.pal(3, "RdYlBu")[3], brewer.pal(3, "RdYlBu")[2], brewer.pal(3, "RdYlBu")[1])
)
Heatmap(
  heatmap_data,
  col = colour2,
  column_names_side = "top",
  cluster_columns = FALSE,
  cluster_rows = FALSE,
  row_order = match(results$name[1:20], rownames(heatmap_data)),
  column_split = data$condition,
  column_gap = unit(2, "mm"),
  heatmap_legend_param = list(title = "log2 Intensity", title_position = "leftcenter-rot"),
)
```
